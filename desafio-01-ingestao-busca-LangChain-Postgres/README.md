# ü§ñ Assistente IA RAG - Sistema de Busca Sem√¢ntica com LLM e banco Postgres

<div align="center">
  
  ![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
  ![LangChain](https://img.shields.io/badge/LangChain-0.3.27-green.svg)
  ![PostgreSQL](https://img.shields.io/badge/PostgreSQL-17-336791.svg)
  ![OpenAI](https://img.shields.io/badge/OpenAI-API-412991.svg)
  ![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)
    

</div>

---

## üìñ Sobre

Este projeto implementa um **Assistente IA com RAG** (Retrieval-Augmented Generation) que permite carregar documentos PDF, processar seu conte√∫do e fazer perguntas contextualizadas sobre o material. O sistema utiliza embeddings vetoriais para busca sem√¢ntica e modelos de linguagem para gerar respostas precisas baseadas apenas no contexto dos documentos carregados.

### ‚ú® Principais Funcionalidades

- üìÑ **Ingest√£o de Documentos PDF**: Carregamento e processamento autom√°tico de arquivos PDF
- üîç **Busca Sem√¢ntica Avan√ßada**: Utiliza embeddings OpenAI para encontrar informa√ß√µes relevantes
- üí¨ **Chat Contextualizado**: Respostas baseadas exclusivamente no conte√∫do dos documentos
- üé® **Interface CLI Interativa**: Terminal colorido e amig√°vel com feedback visual
- üóÑÔ∏è **Armazenamento Vetorial**: PostgreSQL com pgvector para persist√™ncia eficiente
- ‚ö° **Performance Otimizada**: Chunking inteligente e cache de embeddings


## üöÄ Instala√ß√£o

### Pr√©-requisitos

- **Python 3.9+**
- **Docker e Docker Compose**
- **Conta OpenAI com API Key**
- **Conta GoogleAI com API Key**

### üìã Passo a Passo

#### 1Ô∏è‚É£ Clone o Reposit√≥rio

```bash
git clone https://github.com/kaioferreiira/mba-ia-desafios.git
cd desafio-01-ingestao-busca-LangChain-Postgres
```

#### 2Ô∏è‚É£ Acesse a Pasta do Projeto

```bash
# Navegue at√© a pasta espec√≠fica deste projeto
cd desafio-01-ingestao-busca-LangChain-Postgres
```

#### 3Ô∏è‚É£ Configure o Ambiente Virtual

```bash
# Criar ambiente virtual
python3 -m venv venv

# Ativar ambiente virtual
    # Linux/Mac:
    source venv/bin/activate

    # Windows:
    venv\Scripts\activate

# Desativar ambiente virtual
deactivate
```

#### 4Ô∏è‚É£ Instale as Depend√™ncias

```bash
pip install -r requirements.txt
```

#### 5Ô∏è‚É£ Configure as Vari√°veis de Ambiente

Crie um arquivo `.env` na raiz do projeto (copie do `.env.example` se dispon√≠vel) com as seguintes vari√°veis:

```env
GOOGLE_API_KEY=""
GOOGLE_EMBEDDING_MODEL='models/embedding-001'
OPENAI_API_KEY=""
OPENAI_MODEL_CHAT=gpt-3.5-turbo
OPENAI_EMBEDDING_MODEL='text-embedding-3-small'
DATABASE_URL=postgresql://postgres:postgres@127.0.0.1:5432/rag
PG_VECTOR_COLLECTION_NAME=collection_documents_prompts
PDF_PATH="PASTA LOCAL CONTENDO PDF"

```

> üí° **Dica**: Obtenha sua API Key em [platform.openai.com/api-keys](https://platform.openai.com/api-keys)

#### 6Ô∏è‚É£ Inicie o Banco de Dados

```bash
# Iniciar PostgreSQL com pgvector
sudo docker compose up -d

# Verificar se est√° rodando
sudo docker compose ps
```
> üí° **Dica**: Ao rodar o comando compose, pode ser que ja exista algumas instancias docker com a imagem, para n√£o gerar conflitos e criar uma ambiente do zero rode os comandos a seguir para excluir as imagens existentes, e na sequencia execute o compose novamnte. 

```bash
# stop em todas as imagens
sudo docker stop $(sudo docker ps -a -q)

# remover todas as imagens
sudo docker rm $(sudo docker ps -a -q)
```



## üéÆ Como Usar

### Iniciando o Assistente

```bash
python src/chat.py
```

### Interface em Execu√ß√£o

## Execu√ß√£o sem a carga de dados do  PDF

O arquivo ingest_pdf √© respons√°vel por realizar a leitura e fazer a carga no banco de dados Postgress vetorial.
Ao executar o chat sem a carga o assistente dever√° responder que n√£o pode ajudar.

![Execu√ß√£o sem a carga](exe-sem-dados-na-base.png)


## Execu√ß√£o com a carga de dados do  PDF

![Execu√ß√£o com a carga](exe-com-dados-na-base.png)


## üõ†Ô∏è Stack Tecnol√≥gica

### Core
- **[LangChain](https://langchain.com/)** (v0.3.27) - Framework para aplica√ß√µes LLM
- **[OpenAI API](https://openai.com/)** - Embeddings e modelo de linguagem
- **[PostgreSQL](https://www.postgresql.org/)** (v17) - Banco de dados principal
- **[pgvector](https://github.com/pgvector/pgvector)** - Extens√£o para busca vetorial

### Bibliotecas Python
- **langchain-openai** - Integra√ß√£o com OpenAI
- **langchain-postgres** - Integra√ß√£o com PostgreSQL/pgvector
- **pypdf** - Processamento de arquivos PDF
- **python-dotenv** - Gerenciamento de vari√°veis de ambiente
- **psycopg** - Driver PostgreSQL para Python

## üîß Configura√ß√µes Avan√ßadas

### Ajuste de Par√¢metros

Voc√™ pode ajustar os seguintes par√¢metros no c√≥digo:

**Em `ingest.py`:**
```python
# Tamanho dos chunks de texto
chunk_size=1000  # Padr√£o: 1000 caracteres
chunk_overlap=150  # Padr√£o: 150 caracteres de sobreposi√ß√£o
```

**Em `search.py`:**
```python
# N√∫mero de chunks relevantes para contexto
k=10  # Padr√£o: 10 chunks mais similares
```

**Em `chat.py`:**
```python
# Modelo e temperatura
temperature=0.5  # Criatividade das respostas (0-1)
```

